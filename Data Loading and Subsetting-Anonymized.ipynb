{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study 1: Data Loading and Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, all necessary libraries will be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import string\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondy, we imported the self-created dictionaries with different categories of diet-related foods. These dictionaries form the basis of filtering out diet-related messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Input/Dictionaries/foods.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    foods = json.load(fi)\n",
    "\n",
    "with open('Input/Dictionaries/foods_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    foods_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/embeddings.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    embeddings = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/embeddings_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    embeddings_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/dutch_meals.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    dutch_meals = json.load(fi)\n",
    "with open('Input/Dictionaries/dutch_meals_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    dutch_meals_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/meals.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    meals = json.load(fi)\n",
    "with open('Input/Dictionaries/meals_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    meals_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/drinks.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    drinks = json.load(fi)\n",
    "with open('Input/Dictionaries/drinks_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    drinks_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/supermarkets.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    supermarkets = json.load(fi)\n",
    "with open('Input/Dictionaries/supermarkets_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    supermarkets_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/restaurants_cafes.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    restaurants_cafes = json.load(fi)\n",
    "with open('Input/Dictionaries/restaurants_cafes_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    restaurants_cafes_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/diet_related.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    diet_related = json.load(fi)\n",
    "with open('Input/Dictionaries/diet_related_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    diet_related_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/internet_slang.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    internet_slang = json.load(fi)\n",
    "with open('Input/Dictionaries/internet_slang_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    internet_slang_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/food_brands.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    food_brands = json.load(fi)\n",
    "with open('Input/Dictionaries/food_brands_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    food_brands_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/supermarkets.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    supermarkets = json.load(fi)\n",
    "with open('Input/Dictionaries/supermarkets_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    supermarkets_stem = json.load(fi)\n",
    "    \n",
    "with open('Input/Dictionaries/eten_en_drinken.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    eten_en_drinken = json.load(fi)\n",
    "with open('Input/Dictionaries/eten_en_drinken_stem.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    eten_en_drinken_stem = json.load(fi)\n",
    "\n",
    "with open('Input/Nutriscores/nutriscores.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    nutriscores = json.load(fi)\n",
    "\n",
    "with open('Input/Nutriscores/nutriscores_healthy.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    nutriscores_healthy = json.load(fi)\n",
    "    \n",
    "with open('Input/Nutriscores/nutriscores_unhealthy.json', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    nutriscores_unhealthy = json.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eten_en_drinken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, all text messages from the MyMovez dataset from its 7 waves of data collection are imported. Due to privacy reasons, this data cannot be made publicly available. In case that there is interest in the dataset, please contact the corresponding author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buzz_w41 = []\n",
    "buzz_w42 = []\n",
    "buzz_w51 = []\n",
    "buzz_w52 = []\n",
    "buzz_w61 = []\n",
    "buzz_w62 = []\n",
    "buzz_w71 = []\n",
    "buzz_w72 = []\n",
    "BMI = []\n",
    "\n",
    "\n",
    "#with open('Data/Buzz_W4_primary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w41=[r for r in reader]\n",
    "\n",
    "#with open('Data/Buzz_W4_secondary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w42=[r for r in reader]\n",
    "    \n",
    "#with open('Data/Buzz_W5_primary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w51=[r for r in reader]\n",
    "\n",
    "#with open('Data/Buzz_W5_secondary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w52=[r for r in reader]\n",
    "\n",
    "#with open('Data/Buzz_W6_primary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w61=[r for r in reader]\n",
    "\n",
    "#with open('Data/Buzz_W6_secondary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w62=[r for r in reader]\n",
    "    \n",
    "#with open('Data/Buzz_W7_primary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w71=[r for r in reader]\n",
    "\n",
    "#with open('Data/Buzz_W7_secondary-schools.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #buzz_w72=[r for r in reader]\n",
    "    \n",
    "#with open('Data/BMI_final.csv', encoding='utf-8', errors = 'ignore', mode = 'r') as fi:\n",
    "    #reader=csv.reader(fi, delimiter=\";\")\n",
    "    #next(reader) #skip first line\n",
    "    #BMI=[r for r in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All text messages ill be combined to to one single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442616"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_buzz = buzz_w41 + buzz_w42 + buzz_w51 + buzz_w52 + buzz_w61 + buzz_w62 + buzz_w71 + buzz_w72\n",
    "#len(all_buzz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the columns which are of interest for us were selected, which where Sender and Text characteristics. For this we create a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMI_df = pd.DataFrame(columns = [\"Child\", \"BMI\"])\n",
    "d#f_buzz2 = pd.DataFrame(columns = [\"Sender\", \"Child\", \"UMID\", \"Text\", \"Recipient\", \"Type\", \"Likes\", \"Gender\", \"Age\", \"Media\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create one dataframe only for sender characeristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_child = pd.DataFrame(columns = [\"Sender\", \"Child\"])\n",
    "\n",
    "#for message in all_buzz:\n",
    "    #df_child = df_child.append({'Sender': message[0], \"Child\": message[3]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One for message characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for message in all_buzz:\n",
    "    #df_buzz2 = df_buzz2.append({'Sender': message[0], \"UMID\": message[9], \"Child\": message[3], \"Text\": message[15], \"Recipient\": message[13], \"Type\": message[12], \"Likes\": message[22], \"Gender\": message[4], \"Age\": message[5], \"Media\": message[16]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one for health characteristics of the child (his/her BMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rows in BMI:\n",
    "    #BMI_df = BMI_df.append({'Child': rows[0], \"BMI\": rows[6]}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMI_total = pd.merge(df_child, BMI_df, on='Child')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the final dataframe for subsequent use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buzz2.to_csv(r'Input/Text/buzz5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal.to_csv(r'Input/Text/personal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not allowed to present the children messages. But this is how the data-structure without \"Text\" looks like at this moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "buzz = pd.read_csv('Input/Text/buzz_anon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Child</th>\n",
       "      <th>UMID</th>\n",
       "      <th>Recipient</th>\n",
       "      <th>Type</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31296</td>\n",
       "      <td>3.410302e+09</td>\n",
       "      <td>my</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31310</td>\n",
       "      <td>3.410302e+09</td>\n",
       "      <td>my</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Animalzz/Animalzz_funny.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sportzz/Sportzz_Pogba-dab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3410302337</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>31672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1      Sender   Child   UMID     Recipient   Type  \\\n",
       "0           0             0  3410302337  2337.0  31296  3.410302e+09     my   \n",
       "1           1             1  3410302337  2337.0  31310  3.410302e+09     my   \n",
       "2           2             2  3410302337  2337.0  31366           NaN  group   \n",
       "3           3             3  3410302337  2337.0  31391           NaN  group   \n",
       "4           4             4  3410302337  2337.0  31394           NaN  group   \n",
       "5           5             5  3410302337  2337.0  31481           NaN  group   \n",
       "6           6             6  3410302337  2337.0  31505           NaN  group   \n",
       "7           7             7  3410302337  2337.0  31527           NaN  group   \n",
       "8           8             8  3410302337  2337.0  31573           NaN  group   \n",
       "9           9             9  3410302337  2337.0  31672           NaN  group   \n",
       "\n",
       "  Likes  Gender   Age                          Media  \n",
       "0     0     0.0  10.0                            NaN  \n",
       "1     0     0.0  10.0                            NaN  \n",
       "2     1     0.0  10.0                            NaN  \n",
       "3     0     0.0  10.0    Animalzz/Animalzz_funny.jpg  \n",
       "4     0     0.0  10.0                            NaN  \n",
       "5     2     0.0  10.0                            NaN  \n",
       "6     0     0.0  10.0                            NaN  \n",
       "7     7     0.0  10.0  Sportzz/Sportzz_Pogba-dab.jpg  \n",
       "8     2     0.0  10.0                            NaN  \n",
       "9     2     0.0  10.0                            NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buzz[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
